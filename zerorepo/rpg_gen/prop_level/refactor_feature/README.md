# Feature Tree Refactoring Module

This module provides a simplified two-step workflow to refactor feature trees generated by `prop_level_agent.py` into organized subgraphs representing functional components.

## Overview

The Feature Tree Refactoring Agent converts flat feature trees into structured subtree organizations using a clean, efficient two-step process:

1. **Step 1: Subtree Planning** - Determines optimal subtree names, count, and purposes
2. **Step 2: Feature Organization** - Assigns feature paths to appropriate subtrees

## Architecture

```
FeatureRefactorAgent
â”œâ”€â”€ Step 1: SubtreePlanning
â”‚   â”œâ”€â”€ Analyzes feature tree structure
â”‚   â”œâ”€â”€ Designs logical subtree organization
â”‚   â””â”€â”€ Plans 3-8 functional components
â”œâ”€â”€ Step 2: FeatureOrganization  
â”‚   â”œâ”€â”€ Assigns features to planned subtrees
â”‚   â”œâ”€â”€ Ensures functional coherence
â”‚   â””â”€â”€ Minimizes unassigned features
â””â”€â”€ Results Generation
    â”œâ”€â”€ Structured subtree outputs
    â”œâ”€â”€ Coverage statistics
    â””â”€â”€ Organization quality metrics
```

## Key Features

### ðŸŽ¯ **Simplified Workflow**
- **No complex iterations**: Clean two-step process
- **No review cycles**: Direct planning â†’ organization
- **Predictable output**: Consistent, structured results

### ðŸ§  **Intelligent Organization**
- **Functional coherence**: Groups related features together
- **Semantic understanding**: Uses LLM reasoning for logical grouping
- **Balanced distribution**: Aims for manageable subtree sizes

### ðŸ”§ **Structured Output**
- **Type safety**: Pydantic models for all outputs
- **Comprehensive results**: Including planning rationale and statistics
- **Memory traces**: Full conversation history for debugging

### âš¡ **Performance Optimized**
- **Efficient API usage**: Minimal LLM calls
- **Batch processing**: Support for multiple repositories
- **Error resilience**: Robust error handling and retries

## Quick Start

### Installation

The module integrates with the existing RPG building system:

```python
from rpg_building.prop_level.refactor_feature import FeatureRefactorAgent
from rpg_building.base.llm_client import LLMConfig
```

### Basic Usage

```python
# Configure LLM
llm_config = LLMConfig(
    provider="openai",
    model="gpt-4", 
    api_key="your-api-key",
    temperature=0.7
)

# Initialize agent
agent = FeatureRefactorAgent(llm_cfg=llm_config)

# Load feature tree (from prop_level_agent.py output)
with open("repo_features.json", 'r') as f:
    data = json.load(f)

feature_tree = data["Feature_tree"]
repo_data = {k: v for k, v in data.items() 
            if k in ["repository_name", "description", "main_purpose"]}

# Run refactoring
result = agent.refactor_feature_tree(feature_tree, repo_data)

# View results
stats = result["statistics"]
print(f"Created {stats['subtree_count']} subtrees")
print(f"Coverage: {stats['coverage_rate']:.1%}")

for subtree in result["refactored_subtrees"]:
    print(f"â€¢ {subtree['name']}: {subtree['feature_count']} features")
    print(f"  Purpose: {subtree['purpose']}")
```

### Command Line Interface

```bash
# Process single file
python cli.py single --input repo_features.json --output-dir results/

# Process directory
python cli.py directory --input feature_files/ --output-dir results/

# Interactive mode
python cli.py interactive --provider openai --model gpt-4

# Custom configuration
python cli.py single --input file.json --provider anthropic --model claude-3-sonnet --temperature 0.5
```

## Input/Output Format

### Input Format
Expects JSON files with the structure generated by `prop_level_agent.py`:

```json
{
    "repository_name": "my_project",
    "description": "Project description",
    "main_purpose": "Main purpose",
    "Feature_tree": {
        "category1": {
            "subcategory1": ["feature1", "feature2"],
            "subcategory2": ["feature3", "feature4"]
        },
        "category2": {
            "subcategory3": ["feature5", "feature6"]
        }
    }
}
```

### Output Format

```json
{
    "repository_name": "my_project",
    "Features": { ... },  // Original feature tree (ZeroRepo checkpoint format)
    "Component": [        // Component-style subtree array
        {
            "name": "Core Algorithms",
            "purpose": "Fundamental algorithmic implementations",
            "estimate_size": 15,
            "actual_size": 12,
            "util_percent": 0.267,  // Percentage of total features
            "refactored_subtree": {
                "algorithm": {
                    "sorting": ["quicksort", "mergesort"],
                    "search": ["binary search", "hash lookup"]
                }
            }
        },
        {
            "name": "Data Structures",
            "purpose": "Essential data structure implementations",
            "estimate_size": 12,
            "actual_size": 10,
            "util_percent": 0.222,
            "refactored_subtree": { ... }
        }
    ],
    "planning_result": {
        "total_subtrees": 4,
        "subtree_plans": [...],
        "reasoning": "Organized by functional domain..."
    },
    "statistics": {
        "original_feature_count": 45,
        "assigned_feature_count": 42,
        "unassigned_feature_count": 3,
        "coverage_rate": 0.933,
        "subtree_count": 4
    }
}
```

## Two-Step Workflow Details

### Step 1: Subtree Planning

**Objective**: Design logical subtree structure

**Input**: 
- Feature tree structure
- Repository metadata

**Process**:
1. Analyzes feature distribution and relationships
2. Identifies natural functional boundaries
3. Designs 3-8 subtrees with clear purposes
4. Estimates appropriate feature counts per subtree

**Output**: 
- Subtree names and purposes
- Organizational reasoning
- Size estimates

**Example Planning Output**:
```json
{
    "total_subtrees": 4,
    "subtree_plans": [
        {
            "name": "Core Algorithms",
            "purpose": "Fundamental algorithmic implementations for sorting, searching, and graph operations",
            "estimated_size": 15
        },
        {
            "name": "Data Structures", 
            "purpose": "Essential data structure implementations and utilities",
            "estimated_size": 12
        },
        {
            "name": "System Infrastructure",
            "purpose": "Memory management, concurrency, and system-level features", 
            "estimated_size": 10
        },
        {
            "name": "Development Workflow",
            "purpose": "Build, test, deployment, and monitoring capabilities",
            "estimated_size": 8
        }
    ],
    "reasoning": "Organized by functional domain to maximize cohesion..."
}
```

### Step 2: Feature Organization (Iterative)

**Objective**: Assign features to planned subtrees through iterative refinement

**Input**:
- All feature paths from original tree
- Planned subtree structure from Step 1

**Iterative Process**:
1. **Initial iteration**: Process bulk of clear feature assignments
2. **Subsequent iterations**: Handle remaining unassigned features
3. **Dynamic tree building**: Updates `refactored_subtree` in each iteration
4. **Progress tracking**: Shows assigned/remaining counts each round
5. **Termination**: Stops when all features assigned or max iterations reached

**Component Building**:
- Each subtree starts with empty `refactored_subtree: {}`
- Features are added incrementally via `apply_changes()`
- Utilization percentage (`util_percent`) calculated at end
- Actual size vs estimated size tracked

**Output Structure** (Component array):
```json
[
    {
        "name": "subtree name",
        "purpose": "subtree purpose",
        "estimate_size": 15,      // From planning step
        "actual_size": 12,        // After organization
        "util_percent": 0.267,    // % of total features
        "refactored_subtree": {}  // Built incrementally
    }
]
```

**Assignment Criteria**:
- **Functional relevance**: Primary purpose alignment
- **Semantic similarity**: Related concepts and operations
- **Usage patterns**: Features used together
- **Domain coherence**: Conceptual relationships

## Configuration

### LLM Settings
```yaml
llm:
  provider: "openai"
  model: "gpt-4"
  temperature: 0.7
  max_tokens: 4096
  timeout: 60.0
```

### Refactoring Parameters
```yaml
refactoring:
  context_window: 3
  max_retries: 3
  
  planning:
    min_subtrees: 3
    max_subtrees: 8
    preferred_subtree_count: 5
  
  organization:
    allow_unassigned: true
    min_features_per_subtree: 5
    max_unassigned_rate: 0.1
```

### Quality Metrics
```yaml
quality:
  min_coverage_rate: 0.85
  max_size_ratio: 3.0
  preferred_distribution: "balanced"
```

## Examples

### Web Framework Repository
```
Input: 24 features across frontend, backend, deployment
Output: 3 subtrees
- "Frontend Components" (9 features): UI, routing, state management
- "Backend Services" (10 features): APIs, database, authentication  
- "Development Infrastructure" (5 features): Build, deployment, monitoring
```

### Machine Learning Pipeline
```
Input: 31 features across data, modeling, deployment
Output: 4 subtrees  
- "Data Processing" (8 features): Ingestion, preprocessing, validation
- "Model Development" (12 features): Training, evaluation, optimization
- "Production Deployment" (7 features): Serving, monitoring, versioning
- "Infrastructure" (4 features): Containerization, scaling, resources
```

### Algorithms Library
```
Input: 45 features across algorithms, data structures, functionality
Output: 5 subtrees
- "Core Algorithms" (12 features): Sorting, searching, graph algorithms
- "Data Structures" (10 features): Trees, hash tables, linear structures
- "System Management" (8 features): Memory, concurrency, error handling  
- "Development Tools" (9 features): Testing, build, deployment
- "Utilities" (6 features): Serialization, monitoring, helpers
```

## Quality Metrics

### Coverage Statistics
- **Coverage Rate**: Percentage of features successfully assigned
- **Distribution Balance**: Size ratio between largest/smallest subtrees
- **Functional Coherence**: Logical consistency within subtrees

### Typical Results
- **Coverage**: 85-95% of features assigned
- **Subtree Count**: 3-6 subtrees for most repositories
- **Balance Ratio**: 2:1 to 3:1 largest to smallest subtree
- **Unassigned Rate**: <10% for well-structured feature trees

## Comparison with Original Implementation

| Aspect | Original (ZeroRepo) | Simplified (This Module) |
|--------|-------------------|-------------------------|
| **Workflow** | Iterative refinement | Two-step process |
| **Complexity** | Multiple review cycles | Direct planning â†’ organization |
| **API Calls** | 10-50+ per repository | 2 per repository |
| **Time** | Several minutes | 30-60 seconds |
| **Predictability** | Variable iterations | Consistent workflow |
| **Error Recovery** | Complex retry logic | Simple retry mechanism |
| **Output Quality** | Highly refined | Good quality, efficient |

## Advanced Usage

### Batch Processing
```python
from pathlib import Path

# Process multiple files
input_dir = Path("feature_trees/")
output_dir = Path("refactored_results/")

for json_file in input_dir.glob("*.json"):
    result = process_feature_file(
        input_file=str(json_file),
        output_dir=str(output_dir), 
        llm_cfg=llm_config
    )
    print(f"Processed {json_file.name}: {result['statistics']['subtree_count']} subtrees")
```

### Custom Analysis
```python
# Analyze results
def analyze_refactoring_quality(result):
    stats = result["statistics"]
    
    coverage = stats["coverage_rate"]
    balance = max(s["feature_count"] for s in result["refactored_subtrees"]) / \
              min(s["feature_count"] for s in result["refactored_subtrees"])
    
    quality_score = coverage * (1 - min(balance - 1, 1) * 0.3)
    
    return {
        "quality_score": quality_score,
        "coverage": coverage,
        "balance_ratio": balance,
        "subtree_count": stats["subtree_count"]
    }
```

### Integration with Existing Workflow
```python
# Complete pipeline: select_feature â†’ refactor_feature
from rpg_building.prop_level.select_feature import PropLevelAgent
from rpg_building.prop_level.refactor_feature import FeatureRefactorAgent

# Step 1: Generate feature tree
feature_agent = PropLevelAgent(...)
feature_result = feature_agent.iterate_feature_tree(repo_data)

# Step 2: Refactor into subtrees  
refactor_agent = FeatureRefactorAgent(...)
subtree_result = refactor_agent.refactor_feature_tree(
    feature_result["Feature_tree"], 
    repo_data
)

print(f"Generated {len(subtree_result['refactored_subtrees'])} functional subtrees")
```

## Troubleshooting

### Common Issues

1. **Low Coverage Rate**
   - Check feature tree structure
   - Verify repository metadata quality
   - Consider adjusting `max_unassigned_rate`

2. **Unbalanced Subtrees**
   - Review subtree planning logic
   - Adjust `preferred_subtree_count`
   - Check for domain-specific patterns

3. **API Failures**
   - Verify API key configuration
   - Check rate limits
   - Increase `max_retries` setting

### Debug Mode
```python
# Enable detailed logging
logging.basicConfig(level=logging.DEBUG)

# Access conversation history
planning_memory = agent.planning_memory.to_dict()
organization_memory = agent.organization_memory.to_dict()
```

## Performance Considerations

### Speed Optimization
- **Efficient prompting**: Minimal, focused prompts
- **Batch processing**: Process multiple files efficiently  
- **Memory management**: Clear conversation history between files

### Cost Optimization
- **Reduced API calls**: Only 2 calls per repository
- **Optimized tokens**: Concise prompts and structured outputs
- **Model selection**: Balance quality vs. cost

### Scaling Guidelines
- **Small repositories** (<20 features): Very fast processing
- **Medium repositories** (20-100 features): Optimal performance
- **Large repositories** (>100 features): May need feature grouping

## Contributing

### Extending Functionality
1. **Add quality metrics**: Implement additional coherence measures
2. **Custom subtree types**: Support domain-specific subtree categories
3. **Visualization**: Generate subtree structure diagrams
4. **Export formats**: Support additional output formats

### Testing
```bash
# Run example usage
python example_usage.py

# Test with sample data
python cli.py interactive

# Validate with real data
python cli.py single --input your_features.json --output-dir test_results/
```

## License

This implementation follows the project's overall licensing terms and maintains compatibility with the existing RPG building system.